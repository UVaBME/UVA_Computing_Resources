{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdcf9994",
   "metadata": {},
   "source": [
    "# Lesson 3: Introduction to Data Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9c38ce-878e-4158-a23b-6c321eaf6f57",
   "metadata": {},
   "source": [
    "## 0.1 What does data look like?\n",
    "\n",
    "When looking at biological data (or any dataset for that matter), we usually look at a table of **samples** by **features**. Samples may be grouped into classes, may have associated metadata, and are generally independent observations. For example, each sample might be a patient, a particular experiment run, or a single cell.\n",
    "\n",
    "**Features** might also be called characteristics or variables, and they can generally be any type: categorical (`str`, such as disease type), numerical (`float` like expression of a gene or protein level, or `int` like the number of patients that visit a particular hospital), Boolean (`bool`, such as the presence or absence of a particular disease), etc. In `python`, the samples are often the rows and the features are often the columns, like below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ff5383-8ced-4079-89bf-a7aea0ee2f2b",
   "metadata": {},
   "source": [
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b9ef02",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 0.2: What is data analysis?\n",
    "\n",
    "![image](https://almablog-media.s3.ap-south-1.amazonaws.com/Picture_1_080e6f2ab6.png)\n",
    "\n",
    "At this point, we've gone through data manipulation using `numpy` and `pandas`, and basic visualization using `matplotlib`. Whenever using data in research, it's always a great idea to start the same way: **explore the data and visualize it** in simple ways to get a feel for the dataset you are working with. Once you have a good understanding of the data itself, often the next step is to _analyze_ the data. When we refer to data analysis, we are usually talking about **using a computational model or tool to investigate whether the data fits a certain hypothesis.** \n",
    "\n",
    "If your data is labeled into different groups (e.g. case vs. control or a categorical label), you can use _supervised_ approaches to analysis. For example, you can try to **predict** a particular outcome (dependent variable) from several features (independent variables) such as by a **regression** model. Or we can build a model that would **classify** samples into the different known groups. Building such a model would help us identify which features are most important for the distinction between classes. Alternatively, you might want to run some **statistical tests** to see if different groups have significantly different features.\n",
    "\n",
    "If our data is not labeled (or if we are \"blind\" to the labels), we would use an _unsupervised_ approach. For example, you might want to look at the data in fewer dimensions using a **dimensionality reduction** technique. This is an _unsupervised_ way to see patterns in your dataset, and is really useful when the data you are working with has tons of features (which biological data often does, such as expression or activity of several genes/proteins). You also might want to learn whether your data naturally **clusters** into multiple groups with distinct features. This is another _unsupervised_ approach to finding patterns in the data that might have distinct groups. This can be really useful if you are interested in distinct categories in the data; for example, do the cases and controls cluster separately from each other? Do your samples fall into different phenotypes?\n",
    "\n",
    "_Note: technically these unsupervised and supervised approaches are types of machine learning, which is about coding programs that automatically adjust their performance from exposure to information encoded in the data. This is a subfield of Artificial Intelligence. More complicated ML methods, like neural networks, will not be covered in this JumpStart, but they are built on the same foundations as the methods described here. The below chart summarizes many of the algorithms supported by sklearn. Don't worry if you don't recognize these! We will go through a few of them below._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aad340",
   "metadata": {},
   "source": [
    "## 0.3 Representing data in `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffe1530",
   "metadata": {},
   "source": [
    "We will use a package called `scikit-learn` to implement our data analysis. This package includes functions for all of the techniques described above, as well as methods for data wrangling such as normalization and included some built-in datasets useful for testing any models you build.\n",
    "\n",
    "We will import `scikit-learn` below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5585c197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c42aa4",
   "metadata": {},
   "source": [
    "Most algorithms implemented in scikit-learn expect data to be stored in a\n",
    "**two-dimensional array or matrix**.  The arrays can be\n",
    "either ``numpy`` arrays, or in some cases ``scipy.sparse`` matrices.\n",
    "The size of the array is expected to be `[n_samples, n_features]`\n",
    "\n",
    "- **n_samples:**   The number of samples: each sample is an item to process (e.g. classify).\n",
    "  A sample can be a document, a picture, a sound, a video, an astronomical object,\n",
    "  a row in database or CSV file,\n",
    "  or whatever you can describe with a fixed set of quantitative traits.\n",
    "- **n_features:**  The number of features or distinct traits that can be used to describe each\n",
    "  item in a quantitative manner.  Features are generally real-valued, but may be boolean or\n",
    "  discrete-valued in some cases.\n",
    "\n",
    "The number of features must be fixed in advance. However it can be very high dimensional\n",
    "(e.g. millions of features) with most of them being zeros for a given sample. This is a case\n",
    "where `scipy.sparse` matrices can be useful, in that they are\n",
    "much more memory-efficient than numpy arrays.\n",
    "\n",
    "In the code below, we will use a mix of `numpy` arrays (which you learned in Day 1) and `pandas` DataFrames (which you learned earlier today)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f36d50c",
   "metadata": {},
   "source": [
    "We'll start with a basic dataset that is preloaded in sklearn: the iris dataset. You could import this dataset directly from sklearn below, but we already generated a csv file (using the commented out code below) that you'll import instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db32dcac-c60a-481c-856d-158f9e129e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import load_iris\n",
    "# iris = load_iris()\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# iris_df = pd.DataFrame(iris.data, columns=iris.feature_names).assign(species=iris.target_names[iris.target])\n",
    "\n",
    "# iris_df.to_csv('./data/iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6782f922-56f1-4d7b-a0e6-af4ad8095f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris_df = pd.read_csv(\"./data/iris.csv\", index_col = 0, header = 0)\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bb5e41-fc24-467a-a0b5-5fddc7f193d8",
   "metadata": {},
   "source": [
    "### 0.4 Review Problem Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956e840a-5880-47e8-bdb4-3d3ccb5f2e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the blanks below\n",
    "\n",
    "# Can you print out summary statistics for each column in the iris dataset? \n",
    "iris_df.___()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb53b062-e4ab-423f-81e9-86bfe25831e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What data type are each of the features (columns)?\n",
    "iris_df.___()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab63e05-94f0-49da-b0a8-90a882507412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many samples fall into each category of \"species\"?\n",
    "iris_df.___.___()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc0a1a1",
   "metadata": {},
   "source": [
    "## Section 1: Linear Regression\n",
    "\n",
    "We'll start by talking about a model you are probably familiar with from math class: linear regression, also known as finding a line of best fit. In the example below, we will work through a regression problem with one independent variable and one dependent variable, using the iris dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1cf6b2-8a3c-4883-a84a-f52f0c8a43bb",
   "metadata": {},
   "source": [
    "### 1.1 Exploratory analysis\n",
    "\n",
    "To get a sense of whether any of the features in our dataset are correlated, let's plot! We'll use `seaborn` to make a `pairplot`, which plots pairwise relationships in a dataset. This is one case where `seaborn` is much easier than `matplotlib`, because it will automatically make a grid of plots between all of your variables requiring very few arguments in the function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bb178b-154b-4d53-bf8c-469923aa4894",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "# Colab notebook function to make sure the plots show up in the notebook; not needed when running a python file\n",
    "import seaborn as sns # Common abbreviation for seaborn\n",
    "import matplotlib.pyplot as plt # Common abbreviation for matplotlib\n",
    "\n",
    "sns.pairplot(iris_df)\n",
    "plt.show() # not necessary in notebooks, but necessary to show plots in .py files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112e43a1-f947-4bba-8ed1-0e2ad1e342a3",
   "metadata": {},
   "source": [
    "As shown above, `seaborn` function `pairplot` requires only one arguments: the `pandas` DataFrame. However, we can make this plot better by specifying the `hue` parameter to be `species` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de32b3e4-501c-41f6-9237-f1db2e656daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(iris_df, hue = 'species')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ded5972-76fd-49b5-9397-ded09382e271",
   "metadata": {},
   "source": [
    "Now that we've visualized the data, we can see some possible linear relationships between variables (e.g. petal width and sepal length). Let's try to run a regression to see how well these variables are correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2099123d-5207-4707-bc01-8b945ec3f5e3",
   "metadata": {},
   "source": [
    "### 1.3 Build a sklearn Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c435ae2-bbff-47b2-8ead-95af7dc4725b",
   "metadata": {},
   "source": [
    "We will use the sklearn [package](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) for LinearRegression models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016abf41-f098-4dd9-9a04-181f8fad5375",
   "metadata": {},
   "source": [
    "#### Step 1: import the correct module from sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6571f3c-406d-4cd7-99a1-c47619a733ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb7d3e9-18de-40a7-ae56-7e3edbfcc5da",
   "metadata": {},
   "source": [
    "#### Step 2: define the input data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89571be8-05c5-4582-b55f-33f012a12d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array(iris_df['petal width (cm)']).reshape((-1, 1))\n",
    "y = np.array(iris_df['sepal length (cm)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45993b3-be24-4a4d-88b5-2f7c92333967",
   "metadata": {},
   "source": [
    "Notice we defined our independent variable, x, to be the petal width, and our dependent variable, y, to be the petal length.\n",
    "\n",
    "Now, you have two arrays: the input, x, and the output, y. You should call .reshape() on x because this array must be two-dimensional, or more precisely, it must have one column and as many rows as necessary. Thatâ€™s exactly what the argument (-1, 1) of .reshape() specifies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b5567b-5ad1-405c-af91-272f344805ab",
   "metadata": {},
   "source": [
    "The first five samples of x now look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2441b83a-b39b-4f83-a066-dde9acbdff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f0622e-e02a-4b01-a2f7-8cc286cfa8a1",
   "metadata": {},
   "source": [
    "and y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0dc244-bb7a-4bf2-abca-2c9a7cc4f27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a2dbab-a23a-4711-ad37-eaf32fa2b27e",
   "metadata": {},
   "source": [
    "#### Step 3: create a model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a010ce5a-8beb-4f8f-85a7-0a78a9516b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3b1fb6-3a08-4ed9-9493-7cc0ae15f98e",
   "metadata": {},
   "source": [
    "Using the sklearn [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) for LinearRegression models, you can find the section called \"Methods.\" These are all of the possible functions that our model can implement. the LinearRegression model has a method called fit(), which will find the line of best fit using x and y. When you run this, nothing will be returned but the model will be fit to the data we give it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e85034-f42a-4d41-82cf-0d6420d988d6",
   "metadata": {},
   "source": [
    "#### Step 4: fit the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9311ae44-fbf1-4a4b-82c6-bb8338c9d007",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.___(x,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e16a954-2af3-42cd-9297-66fa16cb681c",
   "metadata": {},
   "source": [
    "#### Step 5: Get the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d2ed6d-23b1-45ef-b0dc-e89c2a3c8f5e",
   "metadata": {},
   "source": [
    "We now would like to see the results of our model: for example, we can investigate the correlation using r-squared$^*$ ($r^2$), and we also want to know the intercept and the slope of the line of best fit.\n",
    "\n",
    "$^*$ _The proportion of the variance in the response variable that can be explained by the predictor variable in the regression model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04529c3a-e5cd-429d-b518-ab4acf181afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sq = model.score(x, y)\n",
    "print(f\"coefficient of determination: {r_sq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ff1d3c-7c39-4ab4-baea-4ddade9b079b",
   "metadata": {},
   "source": [
    "What is the equation for the line of best fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5501bbf-8a42-4034-8ddb-6992b06ef0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"intercept:\", model.___)\n",
    "print(\"slope:\", model.___)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf98393-e124-4a9a-8455-87609c33eef4",
   "metadata": {},
   "source": [
    "#### Step 6: Predict new values using a built-in function of the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b961d5fb-3425-4d3c-80be-e1f3b4b2cd78",
   "metadata": {},
   "source": [
    "What about if we have a new datapoint? For example, **if we have a new sample with a petal width of 0.6, what would it's predicted petal length be?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed53ba5-72a7-4341-849a-8293ae39bdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.___(___)\n",
    "print(\"Predicted value\", y_pred)\n",
    "\n",
    "# Predict new values using the line of best fit\n",
    "y_pred = model.___ + model.___ * x\n",
    "print(\"Predicted value\", y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5ff7ba-1a6e-4fa5-89d2-9989ecf41324",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.4: Plotting the model results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350c861d-3ac9-4dbd-b582-782d55cbc5af",
   "metadata": {},
   "source": [
    "There are a few different ways to plot the line of best fit on the plot. Because `matplotlib` function `plot` takes x and y pairs, we will use the model to predict all y values from all x values, and then plot x versus y_pred. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45bee11-f971-4c59-a276-23359b8dc8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b33902-f013-4de2-bb13-c59b194ce84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using matplotlib and/or seaborn, plot a scatterplot of the data with the line of best fit over top.\n",
    "sns.scatterplot(data = iris_df, x = 'petal width (cm)', y = 'sepal length (cm)', hue = 'species')\n",
    "plt.plot(x, y_pred, color = 'black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45659a6-c218-42f6-ae00-b54be942e024",
   "metadata": {},
   "source": [
    "### 1.5 Group practice problem: Best r^2\n",
    "\n",
    "Using the iris dataset, make a new Linear Regression model with the highest possible r^2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e83a06-11b9-40e2-90a2-e5a04f9d4c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbbdcb7-ed30-41ea-81ab-99b029031dec",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<i>Note: while we won't go into the coding details here, you can test how well a model extrapolates to new data by the following steps:</i>\n",
    "1. Split the data into training and testing datasets using `sklearn` function `train_test_split`.\n",
    "2. Fit the model to the training dataset (X_train, y_train).\n",
    "3. Predict the dependent variable in the testing dataset (y_pred from X_test).\n",
    "4. Compare the predicted values to the true values (y_pred vs y_test).\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f330dc-189a-4e10-8373-bd1137ee87f9",
   "metadata": {},
   "source": [
    "## Section 2: Statistical Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e532a510-c7b9-466d-afc3-e229d058401d",
   "metadata": {},
   "source": [
    "## 2.1: T-tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a18418-c994-4d79-9809-800b84bcc24e",
   "metadata": {},
   "source": [
    "We won't be going through all of the mathematical details of a t-test in this course, so if you need a refresher, visit this [page](https://www.pythonfordatascience.org/independent-samples-t-test-python/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b646219c-e637-40e2-b9a2-94fe29082daa",
   "metadata": {},
   "source": [
    "As a brief reminder, a t-test is a parametric test that is testing whether two (independent) groups have the same mean. It requires 3 assumptions to be met:\n",
    "1. Population distributions are normal\n",
    "2. Samples have equal variances\n",
    "3. The two samples are independent\n",
    "\n",
    "We will show a Python function below that actually tests that these assumptions are true."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e277c850-8939-43c1-bd99-bb5a28551129",
   "metadata": {},
   "source": [
    "To do a t-test, we will need to import a new module: `scipy.stats`. As you can probably tell from the name, this will be the go-to python package for statistical testing. This package also includes helpful functions for defining probability distributions, calculating summary statistics, and more advanced methods like Monte Carlo. The base package, `scipy`, can be used for everything from clustering (`cluster`) to fourier transforms (`fft`) to linear algebra (`linalg`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cec45b-524b-41d5-88e7-914c0e6dc21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss #common abbreviation for this package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0ed091-9331-4c06-8ee7-e79b48bb50a8",
   "metadata": {},
   "source": [
    "### Step 1: Decide which variables and groups to test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a261a7a-70a3-4c95-9e02-f0e6518d3cec",
   "metadata": {},
   "source": [
    "We can see from the pairplot we made earlier (reproduced here) that our population distributions for each variable are approximately normal^. We also know from `value_counts()` that we have the same number of samples in each category and that the samples are all independent. While the variances don't appear to be equal for all of the variables, we can see that they are approximately equal for sepal width^, so we'll run a t-test on that variable.\n",
    "\n",
    "^_We can test that the populations are approximately normal using the function `shapiro` and that variances are approximately equal using the function `levene` from `scipy.stats`, which we'll do below._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b487a4-152e-44c0-82ee-02dc9cb38914",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(iris_df, hue = 'species')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d260dc-6373-44b3-9611-9b75498bacd3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "A t-test assumes that the null hypothesis is true:\n",
    "$$H_0: \\mu_1-\\mu_2 = 0$$\n",
    "\n",
    "and then tests whether there is evidence against this assumption. In other words, we want to test if the mean of two groups is significantly different from zero:\n",
    "$$H_A: \\mu_1-\\mu_2 \\neq 0$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4bd0bd-eb4d-4a80-978e-fd098424187f",
   "metadata": {},
   "source": [
    "For a t-test, we need two independent groups. We'll test the sepal width of the Setosa Irises vs the Versicolor Irises (orange vs blue in pairplot above). We'll need to grab all the rows from our dataframe that have `iris_df['species'] == 'setosa'` and put them into a new dataframe, and likewise for the Versicolor Irises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61d4330-10f5-4a45-ae23-82e37f06087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "setosa = iris_df[___]\n",
    "versicolor = iris_df[___]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab6258d-8eb5-49fd-a9ee-e3b4e24fb167",
   "metadata": {},
   "outputs": [],
   "source": [
    "versicolor.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e374bbd-0810-419d-9d53-5d1ec054bcb2",
   "metadata": {},
   "source": [
    "### Step 2: Ensure assumptions for t-test hold "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235696ed-3339-4782-a326-28dda6b26e58",
   "metadata": {},
   "source": [
    "If you don't already know the math behind this step, don't worry about it. The key idea here is that we need to make sure our assumptions are valid: each distribution (in the pairplot above) should look relatively normal and the variance (~ width of the distribution) should be approximately the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a40afb-a18a-4b5d-8b34-4199bfeb8214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that the variances are not significantly different, an assumption of the t-test\n",
    "ss.levene(setosa['sepal width (cm)'], versicolor['sepal width (cm)'])\n",
    "# an insignificant p-value means we can proceed with a t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c87d36-08cb-4c4e-9280-e7232929dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapiro-Wilk test for normality\n",
    "print(ss.shapiro(setosa['sepal width (cm)']))\n",
    "print(ss.shapiro(versicolor['sepal width (cm)']))\n",
    "# an insignificant p-values means each population is not significantly different from a normal distribution, and we can process with a t-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfeb7246-7913-41fe-965f-e10feb676753",
   "metadata": {},
   "source": [
    "### Step 3: Conduct the t-test using `scipy.stats`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc8dd33-324e-4f56-ae13-a640f01e2a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.ttest_ind(setosa['sepal width (cm)'], versicolor['sepal width (cm)'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374dd5cf-3e95-471b-969d-faa1bc3ac784",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "The t-test shows we can reject the null hypothesis that the means are the same. In other words, there is evidence for a statistically significant difference between sepal widths of Setosa Irises and Versicolor Irises.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e38871-ee67-43af-8758-583fae47ebea",
   "metadata": {},
   "source": [
    "## 2.2: Plotting Statistical Tests\n",
    "\n",
    "Often the easiest and best way to plot the results of a statistical test is to use boxplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a55e792-c2ca-4466-acb3-90c8257b2dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are pulling just the two species we want to compare for the boxplot\n",
    "sns.boxplot(data = iris_df[iris_df['species'].isin(['setosa','versicolor'])], \n",
    "            x = 'species', y = 'sepal width (cm)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cece3d-2af7-42cf-b9c1-2e10979b743b",
   "metadata": {},
   "source": [
    "We can use a new [package](https://github.com/trevismd/statannotations) called `statannot` to write on the plot the results of the statistical tests between pairs of groups. Note that `statannot` will run its own version of the test to generate results. Below, we are using the `test` argument to define the test type, `t-test_ind`, which will run pairwise t-tests with a correction (Bonferroni) for multiple comparisons.  We'll use a trick (following the `statannot` documentation) to define the axis `ax` of a figure, plot a boxplot on top, and then add annotations to that same axis `ax`. The `add_stat_annotation` method also outputs the results of the statistical tests if verbose > 0.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Importantly, this package DOES NOT test the assumptions for your chosen statistical test are held before executing the test, so use with caution! Always confirm assumptions hold before running a statistical test.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c6ab47-f725-4217-bf2e-dd956cf3083a",
   "metadata": {},
   "source": [
    "_The below code is some notebook magic that will install a new package. Note that this is NOT how you will usually want to install packages, but can be useful when working in a Google Colab or Jupyter notebook environment._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e649984-996f-4e1d-8da2-adfedf0e8a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install statannot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f004f86a-4bd9-4124-866f-e316d7dc75b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statannot import add_stat_annotation\n",
    "\n",
    "x = \"species\"\n",
    "y = \"sepal width (cm)\"\n",
    "order = ['setosa', 'versicolor']\n",
    "ax = sns.boxplot(data = iris_df[iris_df['species'].isin(order)], \n",
    "            x = x, y = y, order = order)\n",
    "test_results = add_stat_annotation(ax, data=iris_df, x=x, y=y, order=order,\n",
    "                                   box_pairs=[(\"setosa\", \"versicolor\")],\n",
    "                                   test='t-test_ind', text_format='star',\n",
    "                                   loc='inside', verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83cc659-16ac-41d9-ad1d-f41e3fd107f0",
   "metadata": {},
   "source": [
    "The plot below compares all three species in pairwise t-tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68ac1fc-9bde-4dae-938f-f7751a3dcfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statannot import add_stat_annotation\n",
    "\n",
    "# x = \"species\"\n",
    "# y = \"sepal width (cm)\"\n",
    "# order = ['setosa', 'versicolor', 'virginica']\n",
    "# ax = sns.boxplot(data=iris_df, x=x, y=y, order=order)\n",
    "# test_results = add_stat_annotation(ax, data=iris_df, x=x, y=y, order=order,\n",
    "#                                    box_pairs=[(\"setosa\", \"versicolor\"), (\"setosa\", \"virginica\"), (\"versicolor\", \"virginica\")],\n",
    "#                                    test='t-test_ind', text_format='star',\n",
    "#                                    loc='inside', verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6709961-9f69-4cf1-9bee-4b93db67d0d6",
   "metadata": {},
   "source": [
    "### Group Practice: T-test on two other groups for a different variable\n",
    "Run through the t-test for a different variable and any two of the three classes.\n",
    "\n",
    "Hint: Try to test that the assumptions are valid _before_ running the t-test. If you are able to, plot a boxplot to show the results of the t-test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97377a0-776c-440e-a5ba-59f35128e4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "# Group 1: petal width, setosa and virginica\n",
    "# Group 2, petal length, versicolor and virginica\n",
    "# Group 3: sepal length, setosa and versicolor\n",
    "# Group 4: petal width, versicolor and virginica\n",
    "# Group 5: sepal width, versicolor and virginica\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d340b04-887d-4198-829c-024d77a50438",
   "metadata": {},
   "source": [
    "## 2.2: ANOVA\n",
    "\n",
    "If you want to compare multiple independent groups you can use an ANOVA. In `scipy.stats`, this is the `f_oneway` function, which tests the null hypothesis that two or more groups have the same population mean. ([Reference](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.f_oneway.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b5e81d-746f-4023-8bf2-2a8126df32d1",
   "metadata": {},
   "source": [
    "### Group Practice: ANOVA on all three classes\n",
    "Using the documentation above, can you run an ANOVA on all three classes for the sepal length variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ba0f28-63e4-4cdd-871d-c1e09bb09345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "\n",
    "# Hint: if you already defined DataFrames for setosa and versicolor groups, you don't need to redefine them here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c0d0b6-aed7-459a-a246-1da4fa2809c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
